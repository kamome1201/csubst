#! /usr/bin/env python

# omega_asrv can be larger than omega_flat when,
# for example, ASRV is less biased in nonsyonymous substitutions
# for example, # nonsyonymous substs are largely different between branch 1 and branch 2

# TODO: inter-branch distance
# TODO: use IQ-TREE output for ASRV
# TODO: sparse https://sparse.pydata.org/en/stable/

import argparse
import copy
import datetime
import time
from distutils.util import strtobool

from csubst import parser_iqtree
from csubst import parser_phylobayes
from csubst.combination import *
from csubst.genetic_code import *
from csubst.omega import *
from csubst.param import *
from csubst.sequence import *
from csubst.table import *
from csubst.tree import *

csubst_start = time.time()
print('csubst start:', datetime.datetime.now(datetime.timezone.utc), flush=True)

psr = argparse.ArgumentParser()

# Inputs
psr.add_argument('--ncbi_codon_table', metavar='INTEGER', type=int, required=False, default=1,
                 help='default=%(default)s: NCBI codon table ID. See here: '
                      'https://www.ncbi.nlm.nih.gov/Taxonomy/Utils/wprintgc.cgi')
psr.add_argument('--infile_dir', metavar='PATH', type=str, required=True,
                 help='default=%(default)s: PATH to the input file directory.')
psr.add_argument('--infile_type', metavar='[phylobayes|iqtree]', default='iqtree', type=str,
                 choices=['iqtree', 'phylobayes'],
                 help='default=%(default)s: The input file format. PhyloBayes input may not work currently.')
psr.add_argument('--aln_file', metavar='PATH', default='', type=str,
                 help='default=%(default)s: Alignment fasta file. Specify if csubst cannot find it in the infile_dir.')
psr.add_argument('--tre_file', metavar='PATH', default='', type=str,
                 help='default=%(default)s: Rooted newick tree file. Specify if csubst cannot find it in the infile_dir.')

# Foreground specification
psr.add_argument('--foreground', metavar='PATH', default=None, type=str,
                 help='default=%(default)s: Foreground taxa for higher-order analysis.')
psr.add_argument('--exclude_wg', metavar='yes|no', default='yes', type=strtobool,
                 help='default=%(default)s: Set "yes" to exclude branches within individual foreground lineages '
                      'in branch combination analysis.')
psr.add_argument('--fg_sister', metavar='yes|no', default='no', type=strtobool,
                 help='default=%(default)s: Include the sister branches of the foreground stem branches. '
                      'They may serve as "negative controls" relative to the foreground lineages.')
psr.add_argument('--fg_parent', metavar='yes|no', default='no', type=strtobool,
                 help='default=%(default)s: Include the parent branches of the foreground stem branches. '
                      'They may serve as "negative controls" relative to the foreground lineages.')

# branch combinations
psr.add_argument('--max_arity', metavar='INTEGER', default=2, type=int,
                 help='default=%(default)s: The maximum combinatorial number of branches. '
                      'Set 2 for paired substitutions. 3 or larger for higher-order combinations.')
psr.add_argument('--exclude_sisters', metavar='yes|no', default='yes', type=str, choices=['yes', 'no'],
                 help='default=%(default)s: Set "yes" to exclude sister branches in branch combination analysis.')

# Thresholds
psr.add_argument('--ml_anc', metavar='yes|no', default='yes', type=strtobool,
                 help='default=%(default)s: Maximum-likelihood-like analysis by binarizing ancestral states.')
psr.add_argument('--min_sub_pp', metavar='FLOAT', default=0, type=float,
                 help='default=%(default)s: The minimum posterior probability of single substitutions to count. '
                      'Set 0 for a full Bayesian counting without binarization. Omitted if --ml_anc is set to "yes".')
psr.add_argument('--target_stat', metavar='[omega_conv|omega_pair|QNany2spe...]', default='omega_conv', type=str,
                 help='default=%(default)s: The statistics used to explore higher-order branch combinations.')
psr.add_argument('--min_stat', metavar='FLOAT', default=1.0, type=float,
                 help='default=%(default)s: If a branch combination has a target_stat value greater than this value, '
                      'higher-order combinations are explored.')
psr.add_argument('--min_branch_sub', metavar='FLOAT', default=1.0, type=float,
                 help='default=%(default)s: Minimum substitutions in a branch. '
                      'Branches < min_branch_sub are excluded from branch combination analyses.')
psr.add_argument('--min_Nany2spe', metavar='FLOAT', default=1.0, type=float,
                 help='default=%(default)s: Minimum nonsonymous convergent substitutions. '
                      'Branch combinations < min_Nany2spe are excluded from higher-order analyses.')

# Outputs
psr.add_argument('--b', metavar='yes|no', default='yes', type=strtobool,
                 help='default=%(default)s: Branch output. Set "yes" to generate the output.')
psr.add_argument('--s', metavar='yes|no', default='no', type=strtobool,
                 help='default=%(default)s: Site output. Set "yes" to generate the output.')
psr.add_argument('--cs', metavar='yes|no', default='no', type=strtobool,
                 help='default=%(default)s: Combinatorial-site output. Set "yes" to generate the output.')
psr.add_argument('--cb', metavar='yes|no', default='yes', type=strtobool,
                 help='default=%(default)s: Combinatorial-branch output. Set "yes" to generate the output.')
psr.add_argument('--bs', metavar='yes|no', default='no', type=strtobool,
                 help='default=%(default)s: Branch-site output. 0 or 1. Set "yes" to generate the output.')
psr.add_argument('--cbs', metavar='yes|no', default='no', type=strtobool,
                 help='default=%(default)s: Combinatorial-branch-site output. Set "yes" to generate the output.')

# Omega calculation
psr.add_argument('--calc_omega', metavar='yes|no', default='yes', type=strtobool,
                 help='default=%(default)s: Calculate omega for convergence rate.')
psr.add_argument('--calc_distribution', metavar='yes|no', default='yes', type=strtobool,
                 help='default=%(default)s: Calculate omega for convergence rate.')
psr.add_argument('--omega_method', metavar='[rho|permutation]', default='permutation', type=str,
                 choices=['rho', 'permutation'],
                 help='default=%(default)s: ')
psr.add_argument('--num_subsample', metavar='INTEGER', default=10000, type=int,
                 help='default=%(default)s: Activated if "--omega_method rho". The number of combinatorial branch resampling to estimate rho in higher-order analyses.')
psr.add_argument('--cb_stats', metavar='PATH', default=None, type=str,
                 help='default=%(default)s: Activated if "--omega_method rho". PATH to csubst_cb_stats.tsv. Use precalculated rho parameters in branch combination analysis.')
psr.add_argument('--cb_subsample', metavar='yes|no', default='yes', type=str, choices=['yes', 'no'],
                 help='default=%(default)s: Activated if "--omega_method rho". cb subsample output.')

# Among-site rate variation
psr.add_argument('--asrv', metavar='no|pool|sn|each|file', default='each', type=str, choices=['no','pool','sn','each','file'],
                 help='default=%(default)s: Correct among-site rate variation in omega/quantile calculation.')
psr.add_argument('--asrv_file', metavar='PATH', default='infer', type=str,
                 help='default=%(default)s: Precalculated ASRV file. "infer" to automatically detect IQ-TREE\'s *.rate file.')

# Misc
psr.add_argument('--nslots', metavar='INTEGER', default=1, type=int,
                 help='default=%(default)s: The number of processors for parallel computations.')
psr.add_argument('--version', action='version', version='<the version>')

args = psr.parse_args()
g = get_global_parameters(args)

start = time.time()
print("Reading and parsing input files.", flush=True)
g['current_arity'] = 2
g['codon_table'] = get_codon_table(ncbi_id=g['ncbi_codon_table'])
if g['infile_type'] == 'phylobayes':
    g = parser_phylobayes.get_input_information(g)
    if g['input_data_type'] == 'nuc':
        state_nuc = parser_phylobayes.get_state_tensor(g)
        if (g['calc_omega']):
            state_cdn = calc_omega_state(state_nuc=state_nuc, g=g)
            state_pep = cdn2pep_state(state_cdn=state_cdn, g=g)
    if g['input_data_type'] == 'cdn':
        state_cdn = parser_phylobayes.get_state_tensor(g)
        state_pep = cdn2pep_state(state_cdn=state_cdn, g=g)
elif g['infile_type'] == 'iqtree':
    g = parser_iqtree.get_input_information(g)
    if g['input_data_type'] == 'nuc':
        state_nuc = parser_iqtree.get_state_tensor(g)
        if (g['calc_omega']):
            state_cdn = calc_omega_state(state_nuc=state_nuc, g=g)
            state_pep = cdn2pep_state(state_cdn=state_cdn, g=g)
    if g['input_data_type'] == 'cdn':
        state_cdn = parser_iqtree.get_state_tensor(g)
        state_pep = cdn2pep_state(state_cdn=state_cdn, g=g)

write_alignment(state=state_cdn, orders=g['codon_orders'], outfile='csubst_alignment_codon.fa', g=g)
write_alignment(state=state_pep, orders=g['amino_acid_orders'], outfile='csubst_alignment_aa.fa', g=g)

if not g['foreground'] is None:
    g = get_foreground_branch(g)
    g = get_marginal_branch(g)

g = get_dep_ids(g)
if g['cb_stats'] is None:
    g['df_cb_stats'] = pandas.DataFrame()
else:
    g['df_cb_stats'] = pandas.read_csv(g['cb_stats'], sep='\t', header=0)

tree = copy.deepcopy(g['tree'])
for node in tree.traverse():
    node.name = node.name + '|' + str(node.numerical_label)
tree.write(format=1, outfile='csubst_tree.nwk')

N_tensor = get_substitution_tensor(state_tensor=state_pep, mode='asis', g=g, mmap_attr='N')
sub_branches = numpy.where(N_tensor.sum(axis=(1, 2, 3, 4)) != 0)[0].tolist()
if (g['calc_omega']):
    S_tensor = get_substitution_tensor(state_tensor=state_cdn, mode='syn', g=g, mmap_attr='S')
    sub_branches = list(set(sub_branches).union(set(numpy.where(S_tensor.sum(axis=(1, 2, 3, 4)) != 0)[0].tolist())))
g['sub_branches'] = sub_branches

id_combinations = get_node_combinations(g=g, arity=g['current_arity'], check_attr="name")

S_total = numpy.nan_to_num(S_tensor).sum(axis=(0, 1, 2, 3, 4))
N_total = numpy.nan_to_num(N_tensor).sum(axis=(0, 1, 2, 3, 4))
num_branch = g['num_node'] - 1
num_site = S_tensor.shape[2]
print('Synonymous substitutions / tree = {:,}'.format(S_total), flush=True)
print('Nonsynonymous substitutions / tree = {:,}'.format(N_total), flush=True)
print('Synonymous substitutions / branch =', S_total / num_branch, flush=True)
print('Nonsynonymous substitutions / branch =', N_total / num_branch, flush=True)
print('Synonymous substitutions / site =', S_total / num_site, flush=True)
print('Nonsynonymous substitutions / site =', N_total / num_site, flush=True)
elapsed_time = int(time.time() - start)
print(("elapsed_time: {0}".format(elapsed_time)) + "[sec]\n", flush=True)

if (g['bs']):
    start = time.time()
    print("Making branch-site table.", flush=True)
    bs = get_bs(S_tensor, N_tensor)
    bs = sort_labels(df=bs)
    bs.to_csv("csubst_bs.tsv", sep="\t", index=False, float_format='%.4f', chunksize=10000)
    print(bs.info(verbose=False, max_cols=0, memory_usage=True, null_counts=False), flush=True)
    del bs
    elapsed_time = int(time.time() - start)
    print(("elapsed_time: {0}".format(elapsed_time)) + "[sec]\n", flush=True)

del state_cdn, state_pep

if (g['b']) | (g['cb']):
    start = time.time()
    print("Making branch table.", flush=True)
    bS = get_b(g, S_tensor, attr='S')
    bN = get_b(g, N_tensor, attr='N')
    b = merge_tables(bS, bN)
    txt = 'Number of {} patterns among {:,} branches={:,}, min={:,}, max={:,}'
    for key in ['S_sub', 'N_sub']:
        p = b.loc[:, key].drop_duplicates().values
        print(txt.format(key, b.shape[0], p.shape[0], p.min(), p.max()), flush=True)
    del bS, bN
    if (g['b']):
        b.to_csv("csubst_b.tsv", sep="\t", index=False, float_format='%.4f', chunksize=10000)
    print(b.info(verbose=False, max_cols=0, memory_usage=True, null_counts=False), flush=True)
    elapsed_time = int(time.time() - start)
    print(("elapsed_time: {0}".format(elapsed_time)) + "[sec]\n", flush=True)

if (g['s']) | (g['cb']):
    start = time.time()
    print("Making site table.", flush=True)
    sS = get_s(S_tensor, attr='S')
    sN = get_s(N_tensor, attr='N')
    s = merge_tables(sS, sN)
    g['sub_sites'] = dict()
    if (g['asrv']=='no'):
        g['sub_sites']['no'] = numpy.ones(shape=(1, num_site)) / num_site
    elif (g['asrv']=='pool'):
        sub_sites = sS['S_sub'].values + sN['N_sub'].values
        sub_sites = get_relative_sub_sites(sub_sites)
        g['sub_sites']['pool'] = sub_sites
        del sub_sites
    elif (g['asrv']=='sn'):
        for SN,df in zip(['S','N'],[sS,sN]):
            sub_sites = df[SN+'_sub'].values
            sub_sites = get_relative_sub_sites(sub_sites)
            g['sub_sites'][SN] = sub_sites
        del sub_sites
    elif (g['asrv']=='each'):
        g['sub_sites']['each'] = 'Site probability will be calculated in each iteration'
    elif (g['asrv']=='file'):
        if (g['asrv_file']=='infer'):
            file_path = g['aln_file']+'.rate'
        else:
            file_path = g['asrv_file']
        assert os.path.exists(file_path), 'IQ-TREE\'s .rate file was not detected. Please specify file PATH in --asrv_file.'
        print('IQ-TREE\'s .rate file was detected. Loading.')
        sub_sites = pandas.read_csv(file_path, sep='\t', header=0, comment='#')
        sub_sites = sub_sites.loc[:,'C_Rate'].values
        sub_sites = get_relative_sub_sites(sub_sites)
        g['sub_sites'][g['asrv']] = sub_sites
        del sub_sites
    del sS, sN
    if (g['s']):
        s.to_csv("csubst_s.tsv", sep="\t", index=False, float_format='%.4f', chunksize=10000)
    print(s.info(verbose=False, max_cols=0, memory_usage=True, null_counts=False), flush=True)
    elapsed_time = int(time.time() - start)
    print(("elapsed_time: {0}".format(elapsed_time)) + "[sec]\n", flush=True)

if (g['cs']):
    start = time.time()
    print("Making combinat-site table.", flush=True)
    csS = get_cs(id_combinations, S_tensor, attr='S')
    csN = get_cs(id_combinations, N_tensor, attr='N')
    cs = merge_tables(csS, csN)
    del csS, csN
    cs.to_csv("csubst_cs.tsv", sep="\t", index=False, float_format='%.4f', chunksize=10000)
    print(cs.info(verbose=False, max_cols=0, memory_usage=True, null_counts=False), flush=True)
    del cs
    elapsed_time = int(time.time() - start)
    print(("elapsed_time: {0}".format(elapsed_time)) + "[sec]\n", flush=True)

if (g['cbs']):
    start = time.time()
    print("Making combinat-branch-site table.", flush=True)
    cbsS = get_cbs(id_combinations, S_tensor, attr='S', g=g)
    cbsN = get_cbs(id_combinations, N_tensor, attr='N', g=g)
    cbs = merge_tables(cbsS, cbsN)
    del cbsS, cbsN
    cbs.to_csv("csubst_cbs.tsv", sep="\t", index=False, float_format='%.4f', chunksize=10000)
    print(cbs.info(verbose=False, max_cols=0, memory_usage=True, null_counts=False), flush=True)
    del cbs
    elapsed_time = int(time.time() - start)
    print(("elapsed_time: {0}".format(elapsed_time)) + "[sec]\n", flush=True)

if (g['cb']):
    end_flag = 0
    df_rho = pandas.DataFrame([])
    # noinspection PyInterpreter,PyInterpreter
    for current_arity in numpy.arange(g['current_arity'], g['max_arity'] + 1):
        start = time.time()
        print("Making combinat-branch table. Arity =", current_arity, flush=True)
        g['current_arity'] = current_arity
        if (current_arity == 2) & (g['foreground'] is None):
            id_combinations = id_combinations
        elif (current_arity == 2) & (not g['foreground'] is None):
            id_combinations = get_node_combinations(g=g, target_nodes=g['fg_id'], arity=current_arity,
                                                    check_attr='name', foreground=True)
        elif current_arity > 2:
            is_stat_enough = (cb[g['target_stat']] >= g['min_stat']) | (cb[g['target_stat']].isnull())
            is_Nany2spe_enough = (cb['Nany2spe'] >= g['min_Nany2spe'])
            is_branch_sub_enough = True
            for a in numpy.arange(current_arity - 1):
                target_columns = ['S_sub_' + str(a + 1), 'N_sub_' + str(a + 1)]
                is_branch_sub_enough = is_branch_sub_enough & (
                            cb.loc[:, target_columns].sum(axis=1) >= g['min_branch_sub'])
            num_branch_ids = (is_stat_enough).sum()
            print('Arity =', current_arity, ': qualified combinations =', num_branch_ids)
            id_columns = cb.columns[cb.columns.str.startswith('branch_id_')]
            conditions = (is_stat_enough) & (is_branch_sub_enough) & (is_Nany2spe_enough)
            branch_ids = cb.loc[conditions, id_columns].values
            if len(set(branch_ids.ravel().tolist())) < current_arity:
                end_flag = 1
                break
            del cb
            id_combinations = get_node_combinations(g=g, target_nodes=branch_ids, arity=current_arity,
                                                    check_attr='name', foreground=True)
            if id_combinations.shape[0] == 0:
                end_flag = 1
                break
        cbS = get_cb(id_combinations, S_tensor, g, 'S')
        cbN = get_cb(id_combinations, N_tensor, g, 'N')
        cb = merge_tables(cbS, cbN)
        del cbS, cbN
        cb = get_node_distance(tree, cb)
        cb = get_substitutions_per_branch(cb, b, g)
        cb = calc_substitution_patterns(cb)
        cb, g = calc_omega(cb, b, S_tensor, N_tensor, g)
        file_name = "csubst_cb_" + str(current_arity) + ".tsv"
        cb.to_csv(file_name, sep="\t", index=False, float_format='%.4f', chunksize=10000)
        print(cb.info(verbose=False, max_cols=0, memory_usage=True, null_counts=False), flush=True)
        elapsed_time = int(time.time() - start)
        if (g['omega_method'] == 'rho') & (g['cb_subsample'] == 'yes'):
            if 'elapsed_sec' not in g['df_cb_stats'].columns:
                g['df_cb_stats']['elapsed_sec'] = numpy.nan
            g['df_cb_stats'].loc[(g['df_cb_stats']['arity'] == g['current_arity']), 'elapsed_sec'] = elapsed_time
            g['df_cb_stats'] = g['df_cb_stats'].loc[:, sorted(g['df_cb_stats'].columns.tolist())]
            g['df_cb_stats'].to_csv('csubst_cb_stats.tsv', sep="\t", index=False, float_format='%.4f', chunksize=10000)
        print(("elapsed_time: {0}".format(elapsed_time)) + "[sec]\n", flush=True)
    if end_flag:
        print('No combination satisfied phylogenetic independency. Ending branch combination analysis.')

tmp_files = [f for f in os.listdir() if f.startswith('tmp.csubst.')]
_ = [os.remove(ts) for ts in tmp_files]

txt = "\ncsubst completed. Elapsed time = {:,} sec"
print(txt.format(int(time.time() - csubst_start)), flush=True)
print('csubst end:', datetime.datetime.now(datetime.timezone.utc), flush=True)
